<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Learning on InCenger Blog</title>
    <link>https://incenger.github.io/categories/learning/</link>
    <description>Recent content in Learning on InCenger Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Sat, 23 Oct 2021 21:37:44 +0700</lastBuildDate><atom:link href="https://incenger.github.io/categories/learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mình thi IELTS (Indicator)</title>
      <link>https://incenger.github.io/post/learn/ielts_1/</link>
      <pubDate>Sat, 23 Oct 2021 21:37:44 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/ielts_1/</guid>
      <description>
        
          &lt;p&gt;Bài viết Thesis Reflection đã tạm khép lại hành trình làm luận án của mình và để lại mình một câu hỏi: &amp;ldquo;Viết gì tiếp đây?&amp;rdquo;. Mình phân vân giữa viết gì đó mang tính technical và review một vài quyển sách. Sau một hồi suy nghĩ, mình quyết định quay trở lại giá trị cốt lõi của blog này - điều mà mình luôn muốn truyền tải cho người đọc từ những bài viết đầu tiên - những trải nghiệm của mình. Và bài viết này là về chuyện mình đi thi IELTS.&lt;/p&gt;
&lt;p&gt;Đầu tiên, mình nghĩ nên làm rõ trước vài điều. Bài viết này không nhằm mục đích review đề thi IELTS hay chia sẻ phương pháp tự học IELTS, mặc dù nó sẽ chứa tất cả những nội dung đó. Nếu các bạn đang trông đội những nội dung đó thì những group IELTS sẽ là nơi tìm kiếm hiệu quả hơn. Ở đây chỉ có những trải nghiệm của mình mà thôi :)).&lt;/p&gt;
&lt;p&gt;Bài viết này sẽ được chia ra làm 2 phần: Chuyện mình đi thi IELTS và chuyện mình học IELTS. Mình định gộp hai phần vào một bài, nhưng mình thấy nó khá dài nên mình sẽ để phần sau cho một bài viết khác trên blog.&lt;/p&gt;
&lt;p&gt;Mình biết đến IELTS từ những năm cấp ba, và bắt đầu học từ năm nhất đại học (ngắt quãng chứ không liên tục). Đối với việc học IELTS, lựa chọn phổ biến mà mình thấy là tập trung học trong khoảng một thời gian rồi sau đó đăng kí thi. Mình nghĩ đây là một chiến lược hợp lý vì nó tối ưu về mặt thời gian cũng như công sức. Tuy vậy, đó không phải là chiến lược mà mình chọn. Mình theo đuổi một kế hoạch dài hạn hơn - nâng cao khả năng tiếng Anh trước và ôn luyện IELTS sau đó. Việc có nhiều thời gian để học giúp mình có thể học tiếng Anh một cái thoải mái hơn, tuy nhiên, nó lại cho mình nhiều thời gian để trì hoãn hơn :)). Sau khi trì hoãn việc thi IELTS vào năm 2 và năm 3 với lý do là bản thân chưa cảm thấy sẵn sàng, mình dần rơi vào tình thế là buộc phải thi dù có sẵn sàng hay không. Cuối cùng, mình quyết định sau khi bảo vệ luận án xong thì sẽ đăng kí thi IELTS. Để chuẩn bị cho việc đó, mình bắt đầu tăng cường thời gian học tiếng Anh mỗi ngày từ tầm từ khoảng tháng 3, và càng tăng dần cho đến ngày thi.&lt;/p&gt;
&lt;p&gt;Và giống như bao dự định giữa đại dịch này, dự định của mình đã không thể diễn ra như ý muốn. Bảo vệ luận án của mình bị dời lại khoảng 1 tháng và các kì thi IELTS đều bị hoãn. Thông thường, việc bị hoãn sẽ tạo điều kiện có thêm thời gian để chuẩn bị cho kì thi, nhưng với mình, nó cũng đi kèm sự áp lực và sự hoang mang. Việc tự học vốn đã hoang mang, nay càng lớn thêm khi những dự định đi kèm với nó đều bị đặt vào giữa làn ranh đổ vỡ. Nhưng mình khá là may mắn. Giữa những ngày tháng chờ đợi đó thì mình phát hiện ra kì thi IELTS Indicator - thi IELTS tại nhà. Mình xem lịch và chọn ra một ngày thi hợp lí - không quá gấp để mình có thời gian chuẩn bị và không quá xa để tránh mình bị cạn kiệt năng lượng.&lt;/p&gt;
&lt;p&gt;Mình bắt đầu vào quá trình ôn luyện IELTS như bao người - làm đề trong những quyển Cambridge, học từ vựng một số chủ đề rồi luyện nói và viết. Do vẫn còn phải làm việc full-time, nên mình không thể dồn hết tâm sức vào việc chuẩn bị được. Mình cố sắp xếp thời gian vào buổi tối và cuối tuần, cố gắng lựa chọn những thời điểm mình có đủ năng lượng để có thể làm bài thi thử. Nhưng trớ trêu thay, càng chuẩn bị thì mình càng thấy có nhiều thứ mình làm chưa tốt và cần cải thiện. Và thế là trước kì thi khoảng 2 tuần, mình bắt đầu gia tăng cường độ tập luyện. Trong khoảng 2 tuần đó, trong đầu của mình chỉ có làm việc và học IELTS lặp đi lại lặp. Thậm chí khi ngủ mình còn mơ về việc thi IELTS. Suy ngẫm lại, mình thấy quyết định này không sáng suốt lắm.&lt;/p&gt;
&lt;p&gt;Ngày thi đến và mình vẫn chưa cảm thấy sẵn sàng cho nó. Lần gần nhất mình có cảm giác này là hồi thi học sinh giỏi quốc gia năm lớp 12. Nhưng mà không còn đường lùi nữa, mình luôn phải tự bảo bản thân là &amp;ldquo;Just do it!&amp;rdquo;. Mình thi IELTS trong 2 ngày, một ngày cho Speaking và một ngày còn lại cho 3 kĩ năng còn lại. Do stress và lo lắng khá nhiều cộng thêm việc luyện tập cường độ cao, mình cảm thấy khá cạn kiệt năng lượng vào ngày thi. Mình đã từng trải qua những kì thi khắc nghiệt và căng thẳng hơn, nhưng mình cảm giác đây là một trong những lần thi mà mình lo lắng nhiều nhất.&lt;/p&gt;
&lt;p&gt;Ngày thi Speaking. Dù đã chuẩn bị khá kĩ lưỡng về webcam, loa, và micro từ hôm trước, nhưng mình đã bị đánh úp bởi Zoom trên Windows. Mình join vào Zoom để thi và nhận ra webcam của mình không hoạt động. Mình bình tĩnh xin phép giám khảo thử join lại. Trước khi join lại, mình cẩn thận bật thử webcam trên app của Windows để xem có trục trặc gì không, kết quả là vẫn hoạt động bình thường. Nhưng Zoom không nghĩ vậy, mình vẫn tiếp tục không thể bật được webcam trong Zoom meeting. Thế là mình xin phép giám khảo restart lại máy tính. Sau khi restart lại xong, Zoom vẫn chịu nhận webcam của mình. Cùng đường, mình xin phép giám khảo restart máy lại lần nữa để thử chuyển sang Linux xem có được không. Giám khảo cho phép nhưng cảnh báo rằng nếu không bật được webcam lần này nữa thì phải dời lịch thi. Và may mắn thay (mình không rõ phải may mắn không) Zoom trên Linux vẫn hoạt động bình thường. Dẫu vậy, mình không còn thời gian để kết nối lại tai nghe, và đành phải dùng loa ngoài và microphone của laptop với hi vọng rằng chất lương âm thanh không quá tệ. Bước vào bài thi Speaking với tâm thế như vậy, mình cũng không còn nhớ những gì đã chuẩn bị nữa và mình trả lời tất cả câu hỏi theo kiểu freestyle.&lt;/p&gt;
&lt;p&gt;Ngày thi 3 kĩ năng còn lại mình may mắn không gặp trục trặc kĩ thuật gì. Trước khi thi, mình cũng chuẩn bị bằng cách tập trung nghe những đoạn tiếng Anh ngắn nhưng một hình thức khởi động giúp mình có thể tập trung tối đa trong lúc thi. Hít một hơi thật sâu, mình bắt đầu bài thi Listening. Section 1 không có gì quá bất ngờ, nhưng 3 sections sau đó là chuyện khác. Tốc độ của 3 sections đều khá là nhanh, và kì dị thay, tất cả 40 câu hỏi Listening của mình đều là điền từ :))). Mình cũng làm kha khá đề Cambridge và cũng hay đọc review đề trong các group, nhưng đề kiểu này thì mình mới thấy lần đầu :))). Kết thúc bài thi Listening, mình biết đây không phải là màn trình diễn mà mình mong đợi. Cố gắng xốc lại tinh thần, mình bước tiếp vào bài thi Reading.&lt;/p&gt;
&lt;p&gt;Bài thi Reading chào đón mình với những dạng câu hỏi khá lạ. Mình thường không gặp vấn đề nhiều với bài thi Reading, nhưng việc bị snowball tự bài thi Listening đã ảnh hưởng tâm lý của mình. Đập ngay vào mặt mình ở Section 1 là một bài viết về choices, về maximizers và satisficers, về việc luôn cố gắng tìm lựa chọn tốt nhất có thể có tác dụng ngược như thế nào. Mình cảm giác bài viết như đang nói về mình, về quá trình mình chuẩn bị cho kì thi này vậy :))). Mình hoàn thành bài thi Reading trong khoảng 50 phút và dành 10 phút còn lại để kiểm tra lại thật kĩ. Tuy nhiên, trong 10 phút cuối đó, mình cảm thấy thật sự cạn năng lượng. Mắt mình cảm thấy mỏi và mình cảm giác không thể đọc hiểu suy luận thêm được nữa. Vì còn bài thi Writing trước mặt, nên mình quyết định không cố kiểm tra nữa mà cố gắng giữ cho tinh thần và thể chất thật ổn. Dẫu đã cố vực dậy tinh thần, mình đã làm bài rất tệ hại trong bài thi Writing. Mình kết thúc kì thi IELTS trong sự thất vọng toàn tập.&lt;/p&gt;
&lt;p&gt;Khoảng một tuần sau thì mình có kết quả. Mình đã chuẩn bị tinh thần để đón nhận một kết quả tệ. Kết quả đúng là tệ, nhưng mà nó không tệ hoàn toàn. Điểm Writing và Listeing thấp hơn mình kì vọng, nhưng hóa ra mình không làm quá tệ trong 2 bài thi còn lại. Mình đạt 8.5 cho cả Reading và Listening, và Overall 7.5.&lt;/p&gt;
&lt;p&gt;Mình khó thể nói là mình hài lòng về kết quả. Trải nghiệm không mấy suôn sẻ này vô tình lại cho mình cơ hội để nhìn nhận lại được nhiều điều. Mình hiểu được sự quan trọng của việc chuẩn bị và việc chọn đúng điểm rơi về năng lượng (hay phong độ). Quan trọng nhất, nó giúp mình hiểu được khả năng của mình đến đâu, và mình cần phải có những thay đổi gì trong phương pháp học tiếng Anh trong chặng đường tiếp theo.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Efficient Sub-pixel Convolution</title>
      <link>https://incenger.github.io/post/learn/efficient_subpixel_conv/</link>
      <pubDate>Sun, 04 Jul 2021 11:43:10 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/efficient_subpixel_conv/</guid>
      <description>
        
          &lt;p&gt;The efficient sub-pixel convolution is proposed in &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and explained in details in &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Since it was introduced, the method has quickly becam  the most popular choice for upsampling layer in Super Resolution networks.
IMHO, the explanation is &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; is very difficult to follow because the way sub-pixel convolution (or &lt;a href=&#34;https://incenger.github.io/post/learn/transposed_conv/&#34;&gt;Transpose Convolution&lt;/a&gt;) is performed in that paper is very confusing.&lt;/p&gt;
&lt;p&gt;In short, the efficient sub-pixel convolution is just a more efficient way to do sub-pixel convolution. Its superiority lies in the &lt;strong&gt;efficiency&lt;/strong&gt;, &lt;strong&gt;not the upsampling quality&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In order to understand how this works, you need to have basic understanding of Transposed convolution. We will use an example of upsampling a \(4\times 4\) feature map to a \(8\times 8\) to see the equivalence between the normal transposed convolution and the efficient sub-pixel convolution  and how the latter method is more efficient.&lt;/p&gt;
&lt;p&gt;Considering a normal convolution with kernel size \(k = 4\), stride \(s = 2\) (stride \(2\) because we want to double the spatial size of the feature map) and padding \(1\). Applying this convolution on a \(8 \times 8\) input results in a \(4 \times 4\)  output feature map. Its corresponding transposed convolution has kernel size \(k&#39; = 4\), stride \(s&#39; = 1\) with padding \(p&#39; = 2\) (The formulation of transposed convolution&amp;rsquo;s output size can be found in &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;), producing \(8 \times 8\) from \(4 \times 4\) input.&lt;/p&gt;
&lt;p&gt;Since the stride \(s = 2\), in addition to padding values around the transposed convolution input, \(s - 1\) zero pixels are added between actual pixels. The transposed convolution&amp;rsquo;s input, after inserting zeros, is: (Green circles are actual pixels, blue are zero padding)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/efficient_subpixel/padded_input.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now we use a \(4 \times 4\) kernel and slide on this feature map to perform convolution. While doing that, noticing the set of weighs in the kernel that are activated at the same time, you can see the pattern. Weights at position at having the same number will be activated -  multiplying with actual pixels - at the same time (For some position at the corner of the feature map, it&amp;rsquo;s possible that only 2 of 4 weight position are activated but it doesn&amp;rsquo;t affect the generalization). While those weights are activated, weights at other position in the kernel receive zero values.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/efficient_subpixel/pattern.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This observation suggests that it&amp;rsquo;s possible to break down the \(4 \times 4\) kernel into four \(2 \times 2\) kernel using the observed pattern. The transposed convolution, therefore, is equivalent to apply four \(2 \times 2\) convolution on the initial feature map (without zero values inserted between actual pixels), followed by rearranging pixels in result feature maps to create the \(8 \times 8\) output. This is exactly what the &lt;strong&gt;efficient sub-pixel convolution&lt;/strong&gt; does. The efficiency comes from doing the convolution with feature map with smaller spatial size and avoiding inserting zeros between pixels.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/efficient_subpixel/decompose.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Is the deconvolution layer the same as a convolutional layer?&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A guide to convolution arithmetic for deep learning&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

        
      </description>
    </item>
    
    <item>
      <title>Tranposed Convolution</title>
      <link>https://incenger.github.io/post/learn/transposed_conv/</link>
      <pubDate>Sun, 04 Jul 2021 11:34:13 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/transposed_conv/</guid>
      <description>
        
          &lt;p&gt;The transposed convolution is also called:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fractionally strided convolution&lt;/li&gt;
&lt;li&gt;Sub-pixel convolution&lt;/li&gt;
&lt;li&gt;Backward convolution&lt;/li&gt;
&lt;li&gt;Deconvolution (The worst name -  it&amp;rsquo;s confused and shouldn&amp;rsquo;t be used at all)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we unroll the input and output feature maps of a convolution operation into vectors from left to right, top to bottom, the convolution could be represented by a matrix multiplication with a spare matrix \(C\). For example, below is a spare matrix for a convolution with kernel size \(3\), stride \(1\), padding \(0\) over a \(4 \times 4\) input, resulting in a \(2\times2\) output.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/transposed_conv/conv_matrix.png&#34; alt=&#34;Matrix representation of convolution&#34;&gt;&lt;/p&gt;
&lt;p&gt;The convolution above transformed the \(16\)-dimensional vector into \(4\)-dimensional vector. With this representation, it&amp;rsquo;s easy that we can do the reverse transform, which is transforming a \(4\)-dimensional input to \(16\)-dimensional input while keeping the original connectivity pattern, with the help of the transposed matrix \(C^T\). This is the underlying principal of the transposed convolution -  swapping the forward and backward pass of the normal convolution.&lt;/p&gt;
&lt;p&gt;One way to think about transposed convolution is by multiplying the scalar in the input feature map with the kernel weights to create immediate results of the output feature map. The position of the immediate result depends on the position of the scale in the input feature map. The final output is the sum of all immediate results.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/transposed_conv/transposed_conv_1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Another way to think about transposed convolution is to apply an equivalent - but much less efficient - direction convolution on input feature map. Imagining the input of transposed convolution being the result of a direction convolution applied on some initial feature map, the transposed convolution can be considered as the operation that recovers the shape of this initial feature map.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; This way of thinking is reasonable because the transposed convolution is the just backward pass of a direction convolution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/transposed_conv/transposed_conv_2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In addition, considering transposed convolution in its relation to a direction convolution gives rise to the relationship between two convolution operations. Given a direct convolution with kernel size \(k\), stride \(s\), padding \(p\), the transposed convolution has the same kernel size \(k&#39; = k\), stride \(s&#39; = 1\) (noted that the stride for convolution of transposed convolution always has stride \(1\)).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When \(p = 0\) (no padding) and \(s = 1\), considering the top left pixel of input of normal convolution, it only contributes to the top left pixel to the output. Therefore, for transposed convolution to maintain this connectivity pattern, it&amp;rsquo;s necessary to add zero padding around the input of transposed convolution. The padding for transposed convolution&amp;rsquo;s input is \(p&#39;=k-1\).&lt;/li&gt;
&lt;li&gt;When padding is used in the normal convolution, it&amp;rsquo;s reasonable to see that we need to reduce the padding of the transposed convolution. This can be explained by the observation that the top-left pixel of the original input (before padded) now contributes to more pixels output. The new padding for transposed convolution&amp;rsquo;s input is \(p&#39; = k - 1 -p\)&lt;/li&gt;
&lt;li&gt;When stride \(s &amp;gt; 1\) is used for normal convolution, the intuition for transposed convolution is to make the sliding window moves slower. This is made possible by adding zero pixels &lt;strong&gt;between&lt;/strong&gt; actual pixel in the input. For normal convolution with stride \(s\), \(s-1\) zero pixels are added between actual in the input. This is where the name &lt;em&gt;fractionally strided convolution&lt;/em&gt; comes from. Strided transposed convolution is commonly used to  increase the spatial size of feature map.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/transposed_conv/transposed_conv_3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A guide to convolution arithmetic for deep learning&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://d2l.ai/chapter_computer-vision/transposed-conv.html&#34;&gt;https://d2l.ai/chapter_computer-vision/transposed-conv.html&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

        
      </description>
    </item>
    
    <item>
      <title>Deformable Alignment</title>
      <link>https://incenger.github.io/post/learn/deformable_alignment/</link>
      <pubDate>Sat, 03 Jul 2021 12:12:52 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/deformable_alignment/</guid>
      <description>
        
          &lt;p&gt;Motion is an intrinsic part of video. It poses a question about how to extract, exploit, and encode motion information when working with video data. When adapting methods for single image for video, it&amp;rsquo;s usually useful to leverage the prior knowledge that frames of the same scene can be approximated by a reference frame and motion information. The motion between frames can be expressed in many forms, but the most natural and intuitive choice is the optical flow - the displacement of pixels. When it comes to Video Super Resolution (VSR), the motion problem can be decomposed into two questions:how to use the temporal information to constrain the problem and how to effectively extract and exploit temporal correspondence. The former question originates from the ill-posed nature of the Video Super Resolution problem. The later question arises from the fact that adjacent frames of the target one are accessible. Developing alignment algorithms that can adaptive extract motion feature and have the capacity to respond with sudden and complex motions is one of the primary goal in VSR problems.&lt;/p&gt;
&lt;p&gt;Early approaches&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;  &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; to exploit motion information in VSR problems can be decomposed into two stages: motion estimation and motion compensation. In the first stage, dense optical flow between reference and target frames are extracted using flow estimation algorithm. In the second stage, reference frames are warped using estimated flow from the first stage, resulting in compensated or aligned frames. Even though motion estimation and compensation are usually performed on frames, it&amp;rsquo;s possible to perform those on feature maps. Those compensated frames or feature maps should encode motion feature that succeeding algorithms in the VSR network can exploit.  Despite benefiting from the development of flow estimation algorithms, integrating state-of-the-art flow estimation algorithms into VSR network is not simply plug-and-play. If the flow estimation network is used offline - that is to generate the optical flow outside of the VSR network, the motion estimation quality is not good enough due to data limitation. On the other hand, it&amp;rsquo;s challenging to train the flow network and VSR network in the end-to-end manner since two network differs in training data and optimization process.&lt;/p&gt;
&lt;p&gt;In order to overcome the limitations of flow-based alignment approach, recent studies have proposed an implicit alignment method using &lt;a href=&#34;https://incenger.github.io/post/learn/deformable_conv/&#34;&gt;Deformable Convolution&lt;/a&gt; &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.  The deformable alignment has the merit of being both effective and trainable in end-to-end manner. Given the reference and neighbor frame (or feature maps), deformable alignment applies deformable convolution on the neighboring frame to align it to the reference frame. The offset for the deformable convolution is learned from both the target and reference features, for example by applying a few convolution layers on the concatenation of the two features.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/deformable_alignment/deformable_alignment.png&#34; alt=&#34;Deformable Alignment &#34;&gt;&lt;/p&gt;
&lt;p&gt;How this method works is extensively studied in &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. In specific, let \(x\) be the input feature, \(y\) is the output of the deformable convolution on \(x\), \(p_k\) and \(\Delta_{k}\) is the \(k\)-the sampling position and its corresponding offset in the sampling grid \(G\) for output position \(p\), we have:&lt;/p&gt;
&lt;p&gt;$$ y = \sum_{k=1}^{|G|} w(p_k) \cdot x \left(p + p_k + \Delta_{k}\right) $$&lt;/p&gt;
&lt;p&gt;The part \(p + p_k + \Delta_{k}\) can be viewed as displacing or warping the pixel at location \(p\) by a displacement of \(p_k + \Delta_{k}\), which is equivalent to image warping in flow-based alignment. The deformable convolution with kernel size \(|G|\), therefore, are capable of generating \(|G|\) warped feature maps, which are later aggregated using a \(1 \times 1\) convolution via the kernel weight \(w\).
In the special case where \(|G| = 1\), the deformable alignment is equivalent to a spatial warping followed by a \(1 \times 1\) convolution - similar to what we want achieve with flow-based alignment. This observation also points out the advantage of deformable alignment: offset diversity - the capacity to generate more than one potential displacement for each pixel. In other words, deformable alignment and flow-based alignment share their same underpinnings with small difference in the offset-diversity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/deformable_alignment/deformable_convolution_decompose.png&#34; alt=&#34;Decomposing Deformable Convolution &#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Frame Recurrent Video Super-Resolution&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Detail revealing Deep Video Super-resolution&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Temporally Deformable Alignment Network for Video Super-Resolution&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;EDVR: Video Restoration With Enhanced Deformable Convolutional Networks&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Understanding Deformable Alignment in Video Super-Resolution&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

        
      </description>
    </item>
    
    <item>
      <title>Deformable Convolution</title>
      <link>https://incenger.github.io/post/learn/deformable_conv/</link>
      <pubDate>Fri, 02 Jul 2021 23:14:09 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/deformable_conv/</guid>
      <description>
        
          &lt;p&gt;In &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, the authors argue that the traditional CNNs are inherently limited to model geometric transformation due to the fixed geometric structures in its building components. Most of popular building blocks of a CNN such as convolution layer, max-pooling, and region of interest pooling all have fixed geometric structures. The convolution layer samples from the input feature map at fixed locations; the max pooling layer reduces the spatial resolution at a fixed rates; and the output feature map of the ROI pooling has fixed no matter the size of the input feature map. As a result, a CNN built on these layers inherently has similar limitation. For example, all activation units in one layer of a CNN could have the same receptive field, which is undesirable especially for high level convolution layer that captures semantic features. This limitation causes CNNs to be less effective in a few visual recognition tasks requiring fine localization such as semantic segmentation as these tasks necessitates the capacity to respond with different object scales and deformation with adaptive receptive fields.&lt;/p&gt;
&lt;p&gt;The adaptiveness of deformable convolution lies in its augmenting offset grids. In specific, considering a traditional 2D convolution operation that can be broken down into two steps: 1 - sampling from the input feature map \( \mathcal{f_{in}} \)  using a rectangular grid \( \mathcal{R} \) and weighted summation of those sampled values using a learnable weight \( \mathcal{w} \). In plain  \( 3 \times 3  \) convolution with stride $1$, the sample grid \( \mathcal{G} \) is:&lt;/p&gt;
&lt;p&gt;$$\mathcal{G} = { (-1, -1), \dots, (0, 0), \dots, (1,1)}$$&lt;/p&gt;
&lt;p&gt;Values in the output feature map \( \mathcal{f_{out}} \) at location \( p \) is defined by:&lt;/p&gt;
&lt;p&gt;$$\mathcal{f_{out}}(p) = \sum_{\mathcal{g} \in \mathcal{G}} w(g) \cdot \mathcal{f}_{in}(p + g)$$&lt;/p&gt;
&lt;p&gt;Deformable convolution augments the sampling grid  \( \mathcal{G} \) using an offset grid \( \mathcal{O} \) having the same size as \( \mathcal{G} \) , resulting in a sampling offset grid \( \mathcal{G&#39;} = \mathcal{G} + \mathcal{O} \).  In succeeding work, a modulated mask \( \mathcal{M} \) is integrated into deformable convolution to further strengthen its capacity. With values lie in the range \( [0, 1] \), the modulated mask allows deformable convolution to suppress information from some particular position in input feature map. The deformable convolution with modulated mask can be expressed as:&lt;/p&gt;
&lt;p&gt;$$\mathcal{f_{out}}(p) = \sum_{i = 1}^{|\mathcal{G}|} w(\mathcal{G}_{i}) \cdot \mathcal{f}_{in}(p + \mathcal{G&#39;}_{i}) \cdot \mathcal{M_{i}} $$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/deformable_convolution/deformable_conv.png&#34; alt=&#34;Visual Explanation of Deformable Convolution&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Deformable Convolutional Networks&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Deformable convnets v2: More deformable, better results&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

        
      </description>
    </item>
    
    <item>
      <title>KMS Hackathon Part 3: Curtain Call</title>
      <link>https://incenger.github.io/post/learn/kmshackathon-p3/</link>
      <pubDate>Sat, 04 Aug 2018 23:21:30 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/kmshackathon-p3/</guid>
      <description>
        
          &lt;p&gt;Hạ Màn&amp;hellip;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p1/&#34;&gt;Phần 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p2/&#34;&gt;Phần 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Phần 3&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;Cuộc vui đã tàn, không gian đã bắt đầu yên ắn hơn. Cái hơi lạnh không phải của màn đêm ngoài kia mà của một dàn máy lạnh đang hoạt động hết công suât làm tôi rùng mình. Cả căn phòng rộng lớn chỉ còn nghe những tiếng lốc cốc trên bàn phím. Có người vẫn miệt mài tiếp tục công việc của mình, có người đã ngủ gục trên bàn, trên nền nhà, trên bất cứ đâu có thể ngủ được. Tôi biết mình vẫn chưa thể nghỉ ngơi bây giờ, mặc dù cơn bù ngủ đã bắt đầu hành hạ tôi. Tôi lại góc phòng lấy một gói snack ăn cho đỡ buồn ngủ. Đêm nay sẽ thú vị đây&amp;hellip;&lt;/p&gt;
&lt;p&gt;Tôi bắt tay vào làm demo cho App của mình. Tôi chưa tự build một Android App hoàn chỉnh nào từ trước đến giờ (tôi không tính những app build theo hướng dẫn của khóa học), nên mọi thứ khá rối rắm. Tôi bắt đầu từ Main Screen, cố tìm những thư viện phù hợp với chức năng mà tôi mong muốn. Có những thư viện có chức năng mà tôi cần, thì tôi không biết cách nào  để sử dụng, còn cái mà tôi  dùng được thì lại không cho tôi những gì tôi muốn. Cứ thế, google, mày mò, chạy thử rồi lại tiếp tục vòng lặp đó. Cuối cùng, tôi cũng tạo ra được một demo tạm chấp nhận được (đầy bug và không thẩm mỹ lắm). Tôi nhìn đồng hồ, lúc này đã là 3h30 sáng. Như vậy, tôi còn khoảng gần 12 tiếng nữa và tôi đã làm gần 20 tiếng liên tục. Lúc này, cơ thể và trí óc của tôi bắt đầu giảm năng suất rõ rệt. Tôi cần nghỉ ngơi để có thể tiếp tục.&lt;/p&gt;
&lt;p&gt;Tôi sẽ rút kinh nghiệm ở những lần Hackathon sau, nếu có ở lại thì phải đêm theo chăn. Mặc dù đã mặc 2 áo nhưng tôi vẫn cảm thấy lạnh vì nhiệt độ máy lạnh thấp quá. Tôi đi quanh phòng, tìm một chỗ ngủ nào đó ấm áp vì sàn nhà giờ đã rất lạnh. Tất cả những đệm ngủ đã được dùng vậy nên tôi đành phải lên tầng trên để ngủ. Hóa ra, đó là một quyết định khá sáng suốt khi ở tầng này ấm hơn ở dưới nhiều. Mặc dù mùi đồ ăn hơi khó chịu nhưng nhìn chung vẫn ổn hơn là nằm trên sàn nhà lạnh nhiều. Tôi nằm gần chỗ ghế chơi PS4 (giờ này chẳng còn ai chơi nữa nên tôi xí luôn chỗ đấy), nhắm mắt với những tính năng demo vẫn lảng vãng trong đầu.
Những gì diễn ra sáng và trưa hôm đó cũng không có gì để kể nhiều. Cả team vẫn làm và chuẩn bị cho buổi thuyết trình vào buổi chiều. Do vậy, tôi sẽ tua nhanh đến phần quyết định.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Pii2SnJ.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;3 &amp;hellip; 2 &amp;hellip; 1! Hết giờ!&amp;rdquo;. Như vậy là 30 tiếng Hackathon đầu tiên của tôi đã hết. Lúc này, tôi đã bắt đầu thấy mệt và muốn tìm một chỗ để ngủ ngay lập tức. Nhưng trước mắt vẫn còn đó là một bài thuyết trình. Tôi sẽ không đi vào chi tiết của nó vì &amp;hellip; đó là một bài thuyết trình thất bải thảm hại. Thời gian giới hạn 5 phút và việc thiếu kinh nghiệm đã làm cho bài thuyết trình của chúng tôi về sản phầm rất tệ. Sau khi thuyết trình và nghe nhận xét xong, tôi lặng lẽ ra góc phòng, thả mình trên ghế, mắt nhìn ra những áng mây chiều phía cuối trời (ngắm mây trời ở thành phố chán hơn nhiều so với ở quê). Tôi không buồn, chính xác hơn, tôi đang tận hưởng những phút giây cuối cùng của cái Hackathon đầu tiên của mình. Tôi chợt khẽ cười, nhận ra rằng mình đã học được nhiều thứ hơn rất nhiều so với chính bản thân mình 30 tiếng trước. Có lẽ, như vậy là đủ cho lần đầu &amp;hellip;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Đây là kết thúc cho 3 phần của series KMS Hackathon, tôi không muốn viết quá sâu vào chi tiết, mà chỉ muốn kể về những điều tôi cảm thấy thú vị trong suốt cuộc thi. Nếu các bạn đã đọc đến dòng này, thì cảm ơn các bạn đã đồng hành với mình qua suốt 3 phần, mặc dù đôi chỗ hơi nhàm chán do mình viết khi buồn ngủ :D.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>KMS Hackathon Part 2: Trouble comes</title>
      <link>https://incenger.github.io/post/learn/kmshackathon-p2/</link>
      <pubDate>Fri, 20 Jul 2018 16:31:50 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/kmshackathon-p2/</guid>
      <description>
        
          &lt;p&gt;Những khó khăn bắt đầu xuất hiện&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p1/&#34;&gt;Phần 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Phần 2&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p3/&#34;&gt;Phần 3&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;Ý tưởng đã có, phần quan trong nhất bây giờ là biến nó thành sản phẩm (ít nhất là demo được). Cả team quyết định làm demo bằng mobile app. Trớ trêu thay, trong cả team, chỉ có mình tôi là đã có kinh nghiệm làm về Android Application. Nói là đã có kinh nghiệm, nhưng thật ra tôi mới chỉ bắt đầu nghịch Android được hơn 1 tháng, và cũng chỉ là học những course của Udacity (các bạn có thể thấy thông qua series &lt;a href=&#34;https://incenger.github.io/tags/android-for-noob/&#34;&gt;Android for Noob&lt;/a&gt; của tôi). Tôi có biết thêm một ít về React Native (tôi chỉ mới học qua được 1, 2 ngày) nhưng vẫn chưa đủ để  áp dụng vào làm một application cơ bản. Vì vậy, việc được giao trách nhiệm làm mobile app thật sự là một thử thách vượt quá khả năng của tôi. Nhưng mà &amp;hellip;, cứ làm thôi :D.&lt;/p&gt;
&lt;p&gt;Ăn trưa xong đã là 1h, còn tổng cộng 26 tiếng nữa, băt đầu vào code thôi. Đầu tiên phải thiết kế UI. May mắn cho tôi là trong trước đó vài ngày, tôi vừa hoàn thành Human Computer Interaction Summer School. Nhờ những chương trình này mà tôi biết được những điều cần làm trong quá trình thiết kế giao diện cho sản phẩm của mình. Tôi bắt đầu lấy giấy ra, sketch từng activity cho app của mình và đưa cho team tôi test để kiểm tra thiết kế đã tiện lợi cho người dùng chưa. Tôi mất gần 2 tiếng (và một đống snack và nước ngọt :D) để định hình được app của mình. Thật lòng mà nói, những gì tôi đã sketch trong prototype vượt xa khả năng hiện tại của tôi, vì vậy tôi thấy khá mông lung về khả năng hoàn thành được demo của mình. Tôi vẫn hay đùa với cả team là &amp;ldquo;Nếu tối nay Bỉ thắng Anh thì mai tụi mày có demo, còn không thì tụi mày hiểu rồi đấy :D&amp;rdquo;. Tiếp theo là những giờ liên tục vừa google, vừa xem code, vừa build thử ra app và cứ thế lặp lại.&lt;/p&gt;
&lt;p&gt;Quá trình build app đôi khi làm tôi nản vì lạc giữa một rừng thư viện UI nhưng lại không có cái nào vừa ý mình. Thêm cả team không có đứa nào biết phần này nên tôi cũng không thể tham khảo ý kiến của tụi nó. Vài giờ đồng hồ trôi qua, app của tôi vẫn chưa có được phiên bản đầu tiên. Tôi quyết định tắt máy, đi lên lầu 7 để đầu óc thư giãn một lúc. Thời gian cứ trôi, tôi không thể cứ đứng yên ở vị trí xuất phát được. Và chính lúc này tôi đã đưa ra một quyết định có ảnh hưởng quan trọng đến khả năng ra đời của cái demo sau này. Tôi quyết định bỏ đi những activity tôi muốn làm nhất, nhưng chưa làm được và tập trung vào những activity thể hiện rõ những tính năng của app.&lt;/p&gt;
&lt;p&gt;Trong khoảng thời gian tôi làm UI cho demo thì cả team của tôi cũng chật vật với những phần khác. Có 2 đứa xác định không thể giúp gì cho việc code nên đã quyết định tìm kiếm những thông tin cần thiết để giới thiệu ý tưởng và làm slide (team tôi bắt đầu làm slide ngay khi cái app còn chưa ra đời :D). Một đứa thử giúp tôi trong phần UI nhưng còn chật vật hơn tôi. Hai đứa còn lại thì một đứa đang chật vật với MongoDB, đứa còn lại thì có khả năng code BlockChain nhưng lại không biết deploy trên Android, và như vậy nghĩa là càng thêm việc để tôi phải tìm hiểu và làm.
Tóm gọi là tình hình của team tôi lúc này là &amp;ldquo;lực bất tòng tâm&amp;rdquo;, khả năng không đủ để thực hiện trọn vẹn ý tưởng của mình.&lt;/p&gt;
&lt;p&gt;Bảy tiếng nữa lại trôi qua, team chúng tôi vẫn mới chỉ hoàn thành được 10% công việc. &amp;ldquo;Đêm nay sẽ dài đây!&amp;rdquo; -  Tôi nghĩ. Trong lúc rối ren đó thì đồ ăn là vị cứu tinh của tôi. Sau bữa trưa khá là hoành tráng, tôi đang trông chờ vào đồ ăn buổi tối. Và ban tổ chức thật sự không làm tôi thất vọng. Buôi tối có cơm và pizza.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/3YF5g1W.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Có mỗi điều trong KMS Hackathon mà tôi thích nhất chính là Code Detox - một tiếng phục vụ cocktail và đàn hát để giúp các team xả stress. Dù công việc chưa đến đâu, nhưng tôi cũng không muốn bỏ lỡ chương trình thú vị này :D. Tôi đã chọn một ly mocktail Sweet Down (tôi chưa dùng cocktail bao giờ nên khi nhìn vào menu, tôi chi chọn ngẫu nhiên cái nào có tên lạ lạ :D).
&lt;img src=&#34;https://i.imgur.com/gIowsWb.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Sau khi uống xong ly mocktail, tôi qua chỗ chơi PS4 để đá Pes một trận (lâu quá rồi không đá Pes nên tôi cứ chuyền với sút bấm loạn lên :D). Ngoài cocktail, ở quầy đồ uống cũng có sẵn Strongbow, xác định đem nay sẽ dài, tôi cầm vài chai để vừa uống vừa code. (Có lẽ quyết định này không sáng suốt lắm&amp;hellip;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/JOqSQJQ.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Như vậy là đã hết ngày đầu tiên, tôi nhận thấy ngoài ăn uống thì mình vẫn chưa làm được gì nhiều. 13 tiếng còn lại sẽ là cuộc chạy đua với thời gian của tôi.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>KMS Hackathon Part 1: The First Hackathon</title>
      <link>https://incenger.github.io/post/learn/kmshackathon-p1/</link>
      <pubDate>Tue, 17 Jul 2018 23:40:59 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/learn/kmshackathon-p1/</guid>
      <description>
        
          &lt;p&gt;Với một thằng noob không chuẩn bị gì thì 30 tiếng hackathon sẽ như thế nào?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Phần 1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p2/&#34;&gt;Phần 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://incenger.github.io/post/learn/kmshackathon-p3/&#34;&gt;Phần 3&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;Một trong những mục tiêu cần hoàn thành trong năm 2018 của tôi là tham gia ít nhất một cuộc thi Hackathon. Khi đặt ra mục tiêu đó, tôi cũng chưa biết chính xác mình cần phải chuẩn bị những gì cho một cuộc thi Hackathon. Tôi nghĩ mục đích chính của tôi chỉ là trải nghiệm cảm giác của một cuộc thi Hackathon mà thôi.&lt;/p&gt;
&lt;p&gt;KMS Hackathon là cuộc thi Hackathon trong 30 tiếng với mục tiêu tạo ảnh hưởng đến xã hội do công ty KMS tổ chức. Chủ đề của cuộc thi là &amp;ldquo;Unemployment&amp;rdquo; được giữ kín cho đến khi bắt đầu Hackathon. Trước khi đến vòng onsite, mỗi team phải vượt qua vòng loại online. Tôi không biết các team khác thấy thế nào, nhưng tôi thấy đề của vòng loại khá dễ , chỉ là 2 bài tập khá đơn giản về đồ thị. Vì vậy, được tham gia Hackathon đối với tôi là một sự bất ngờ. Đó chính là bắt đầu cho những trải nghiệm thú vị của tôi ở cuộc thi Hackathon này.&lt;/p&gt;
&lt;p&gt;Giờ checking của Hackathon là 8h sáng, ban tổ chức cũng tài trợ sẵn 1 code Grab 50k để tiện cho việc di chuyển đối với những team dự thi. Cuộc thi được tổ chức ở trụ sở của KMS ở Tản Viên, Tân Bình. Trụ sở khá hoành tráng nhưng không rộng lắm. Tôi đến vào lúc 7h45, sau khi check in và làm vài thủ tục, tôi được hướng dẫn lên tầng 7.&lt;/p&gt;
&lt;p&gt;Tầng 7 là tầng để giải trí và ăn uống, nhưng có lẽ vì ban tổ chức không thông báo từ đầu, nhiều team đã nghĩ tầng này là tầng diễn ra hackathon nên đã lấy máy tính ra để sẵn rất khí thế =)). Ấn tượng đầu tiên của tôi ở tầng này là đồ ăn =)). Có bánh ngọt, bánh mặn, snack, sữa, nước trái cây, cafe và các loại đồ uống thông thường khác. Ngoài ra còn có một máy PS4, một bàn banh bàn để giải trí khi căng thẳng. Mặc dù đã ăn sáng rồi, nhưng tôi vẫn quyết định dùng thử xem bánh ở đây như thế nào. Tôi không thích bánh mặn lắm, nhưng bánh ngọt thì khá ngon (vì vậy trong suốt cuộc thi tôi đã ăn khá nhiều, không nhớ chính xác là tổng cộng bao nhiêu cái :D). Đây là những món tôi ăn vào lúc đó.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/dsdt9GM.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Ăn xong, tôi đi quanh khám phá các ngóc ngách của tầng 7 trước khi ban tổ chức thông báo tập trung ở tầng 6 để bắt đầu cuộc thi.&lt;/p&gt;
&lt;p&gt;Tầng 6 rất rộng rãi và sáng sủa. Có tổng cộng 27 team tham gia dự thi, mỗi team được được bố trị một bàn và một màn hình máy tính. Ngoài ra mỗi thành viên đều được phát một bộ Hack Kit có chứa 1 gối ngủ, 1 áo và 1 bình nước.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/zqYd5Zb.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/7KTycWo.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Nói sơ qua một chút về team của tôi. Tên của team là &lt;strong&gt;DBT FC&lt;/strong&gt;. Ý nghĩa của tên thật ra là fan club của thầy Tiến :D. Tôi lập team với 5 thằng bạn trong lớp. Nếu xét về khả năng và trình độ thì team tôi thật sự khá hạn chế: có 1 đứa chuyên làm BlockChain, 1 thằng mới tập tành Android và 4 đứa còn lại thì chủ yếu là code &lt;code&gt;C++&lt;/code&gt; để làm bài tập chứ chưa code project lớn bao giờ. Vì vậy có lẽ nói mục tiêu của team là đi để kiếm áo thì cũng không sai =)). Nhưng đã thi rồi, thì dù sao cũng phải cố gắng hết sức.&lt;/p&gt;
&lt;p&gt;9h, ban tổ chức công bố chủ đề và bắt đầu đếm ngược 30 tiếng của Hackathon. Okay, let the hack begin.&lt;/p&gt;
&lt;p&gt;Sau khi nhận đề, cả team của tôi bắt di chuyển lên tầng 7 để bàn về ý tưởng. Sau hơn 2 tiếng vật lộn với một đống ý tưởng và &amp;hellip; một đống đồ ăn, chúng tôi cũng đã tìm được ý tưởng. Bản thân tôi thấy ý tưởng khá hay và khác biệt so với đa số các team. Nhưng với khả năng hiện tại của team, thực hiện được nó là một thử thách không hề nhỏ. Cơ mà cứ thử thôi, tới đâu thì tới :D.&lt;/p&gt;
&lt;p&gt;Bàn ý tưởng xong thì cũng tới giờ ăn trưa. Tuy chỉ là cơm nhưng đồ ăn khá là chất lượng (Có lẽ đồ ăn là điều tôi thích nhất trong hackathon này :D).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Pn0QQ0V.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Ăn xong, cả team bắt đầu bắt tay vào chia công việc và bắt đầu code.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Tôi sẽ dừng lại phần đầu ở đây vì khá buồn ngủ. Trông phần tiếp theo, tôi sẽ tiếp tục với quá trình code, những bi hài trong quá trình làm app và lần đầu uống cocktail của tôi :D&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>First Course</title>
      <link>https://incenger.github.io/post/learn/first-course/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://incenger.github.io/post/learn/first-course/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://i.imgur.com/D8SfStr.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Trong bài viết hôm nay, mình sẽ chia sẻ trải nghiệm của mình về khóa học đầu tiên &lt;a href=&#34;https://www.udacity.com/course/android-basics-user-interface--ud834&#34;&gt;Android Basics: User Interface&lt;/a&gt;.
Khóa học được ước tính học trong 2 tuần, nhưng mình nghĩ nếu có thời gian, các bạn có thể hoàn thành nó trong khoảng 1-3 ngày (mình học trong 1 buổi và làm project trong 1 buổi, còn thời gian cụ thể từng buổi thì mình không nhớ chính xác). Nội dung của khóa học chủ yếu là về những khái niệm cơ bản trong UI: Views, Layout và XML.&lt;/p&gt;
&lt;h1 id=&#34;view&#34;&gt;View&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/kAHn90t.jpg&#34; alt=&#34;&#34; title=&#34;Paper App Screenshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;Bên trên là ảnh chụp màn hình từ app Paper của Dropbox. Một Android app bao gồm nhiều “màn hình” tương tự như vậy - hay còn gọi là layout. Mỗi layout thường gắn liền với một chức năng của app, ví dụ như trong hình là màn hình hiển thị các files của app Paper. Layout chính là nơi xảy ra tương tác giữa người dùng với app của chúng ta thông qua các thao tác chạm, kéo thả, …. Mỗi Layout bao gồm nhiều View với các kích thước và vị trí khác nhau. Để sử dụng View trong Android Studio, chúng ta có 2 cách:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sử dụng công cụ Design trong Android Studio
&lt;img src=&#34;https://i.imgur.com/nyJZekT.jpg&#34; alt=&#34;&#34; title=&#34;Design Mode&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sử dụng code XML
&lt;img src=&#34;https://i.imgur.com/apYA4CW.jpg&#34; alt=&#34;&#34; title=&#34;XML mode&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cả 2 cách này đều có những ưu điểm và nhược điểm riêng. Cá nhân mình thích sử dụng Design mode hơn vì nó trực quan hơn là dùng XML code. Tất nhiên, các bạn nên kết hợp cả 2 cách để có thể thiết kế UI một cách tối ưu.&lt;/p&gt;
&lt;p&gt;Mỗi View trong Android có nội dung đa dạng: TextView, ImageView, Button, … và có thể chứa thêm nhiều View khác bên trong nó. Đối với mỗi View, chúng ta có thể tùy chỉnh các đặc tính của nó như kích thước, màu sắc, …. Smartphone Android rất đa dạng, về cấu hình, kích thước, kiểu dáng, tính năng. Sự đa dạng đó cung cấp nhiều lựa chọn cho người dùng nhưng lại đặt ra một bài toán cho người phát triển làm sao để tối ưu cho các thiết bị mà không phải viết lại code. Sự khác biệt rõ ràng nhất giữa các điện thoại Android (và điện thoại với máy tính bảng) chính là kích thước của màn hình. Vậy khi thiết kế UI cho app, chúng ta phải làm sao để những kích thước, vị trí của những View trong đó không phải phụ thuộc vào kích thước cụ thể nào. Đó là lí do tại sao trong Android, chúng ta nên sử dụng dp (device-independent pixel) làm đơn vị đo kích thước  thay cho px (pixel).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/KGoMUa1.jpg&#34; alt=&#34;&#34; title=&#34;Pixel vs Device-Independent Pixel&#34;&gt;&lt;/p&gt;
&lt;p&gt;#Layout&lt;/p&gt;
&lt;p&gt;Để xây dựng một UI hoàn thiện, ngoài View, chúng ta cần một Layout để chứa những View đó. Có 2 loại Layout được giới thiệu trong khóa học là LinearLayout và  RelativeLayout.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LinearLayout: Đối với LinearLayout, vị trí của các View sẽ được đặt theo hàng hoặc theo cột.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/7xnpbWU.jpg&#34; alt=&#34;&#34; title=&#34;Vertical LinearLayout&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Itaa3gN.jpg&#34; alt=&#34;&#34; title=&#34;Horizontal LinearLayout&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RelativeLayout: Các view sẽ được xác định vị trí dựa vào vị trí của các view khác hoặc vị trí của layout. Một số đặc tính của của nó là : toRightOf,  toLeftOf, above , below, &amp;hellip;. Mỗi View sẽ có một ID do người dùng khai báo trong code XML. Thông qua ID đó, các View khác có thể xác định vị trí.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/nkKW75D.jpg&#34; alt=&#34;&#34; title=&#34;Relative Layout&#34;&gt;&lt;/p&gt;
&lt;p&gt;Ở phần này, mình khá tiếc vì trong khóa không có dạy về &lt;a href=&#34;https://developer.android.com/reference/android/support/constraint/ConstraintLayout&#34;&gt;ConstraintLayout&lt;/a&gt; được Google giới thiệu lần đầu trong Google I/O 2016 (có lẽ vì vậy mà khóa học không có, khóa này bắt đầu từ 2015). ConstraintLayout giúp cải thiện về performance và quan trọng hơn, bạn có thể tạo một layout phức tạp mà không cần phải dùng nhiều LinearLayout và RelativeLayout lồng vào nhau. Nó cũng tận dụng tối ưu được Design Mode trong thiết kế UI. Mình sẽ có một bài viết riêng về ConstraintLayout và những ứng dụng của nó.&lt;/p&gt;
&lt;h1 id=&#34;kết-quả&#34;&gt;Kết quả&lt;/h1&gt;
&lt;p&gt;Sau khi kết thúc khóa học đầu tiên, thành quả của mình chính là 2 app: Cả 2 app rất đơn giản, chỉ bao gồm 1 layout, người dùng vẫn chưa có thể tương tác gì. Nhưng nó đã đáp ứng được mục đích của khóa là về User Interface.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/CeD972P.jpg&#34; alt=&#34;&#34; title=&#34;Happy Birthday App&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Ro6y6fj.jpg&#34; alt=&#34;&#34; title=&#34;Monkey In Black App&#34;&gt;
Nếu các bạn có thể để ý thì ở app thứ 2 , màu sắc và bố cục chưa thật sự ổn lắm. Thật sự là vậy, mình khá tệ trong việc lựa chọn màu sắc, kiểu dáng cũng như là kích thước các view. Mỗi khi thiết kế một UI, mình muốn có một guideline để dựa vào, như vậy UI mình sẽ cân đối về màu sắc và bố cục hơn. Nếu các bạn cũng gặp vấn đề như mình thì có thể xem &lt;a href=&#34;https://material.io/&#34;&gt;Material Design&lt;/a&gt; của Google. Ở đây, các bạn có thể tìm thấy các quy ước về màu sắc, kích cỡ, vị trí để app của bạn nhìn đơn giản nhưng đẹp mắt.
Như vậy thì mình đã hoàn thành khóa học đầu tiên. Tóm lại, trong khóa này mình đã học thêm được:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;XML: syntax và attributes&lt;/li&gt;
&lt;li&gt;Một số loại Views: TextView, ImageView, Button,…&lt;/li&gt;
&lt;li&gt;Hai loại layout: LinearLayout và RelativeLayout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;và đã hoàn thành được 2 app. Mình sẽ dành riêng cho ConstraintLayout trong một bài viết khác vì ConstraintLayout đã thực sự thay đổi các mình thiết kế UI, thay vì code XML thì giờ mình chỉ cần kéo thả một cách rất trực quan. Như mọi lần, mình là một thằng Noob và sẵn sằng tiếp nhận những ý kiến của mọi người.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Nếu các bạn thắc mắc tại sao mình lại chọn Monkey In Black để đưa vào trong app của mình thì MIB chính là quán cafe đầu tiên mà mình đi khi mới vào Sài Gòn học. Mình rất thích Monkey In Black vì những con người, nguồn năng lượng, chất điên mà quán gửi vào từng sản phẩm. Đơn giản vậy thôi :D (Mình không PR giúp quán đâu :D)&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Android Studio and Udacity</title>
      <link>https://incenger.github.io/post/learn/2018-05-15-android-studio-and-udacity/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://incenger.github.io/post/learn/2018-05-15-android-studio-and-udacity/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://i.imgur.com/9dA7VyG.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;android-studio&#34;&gt;Android Studio&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/9QWugQs.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Nhìn qua ảnh, có lẽ các bạn cũng biết mình sẽ nói đến vấn đề gì trong phần này. Android Studio là IDE do Google phát triển với nhiều tính năng hỗ trợ tối đa cho việc lập trình và phát triển app trên Android. Sẽ không có vấn đề gì để nói nếu như mình không đang chạy nó trên một con laptop core i3-5005u với 4Gb ram (Các bạn có thể xem thể về &lt;a href=&#34;https://developer.android.com/studio/&#34;&gt;System Requirements&lt;/a&gt; của Android Studio). Đây là tình trạng máy của mình khi chạy Android Studio và mở song song 1 tab Google Chorme (để học trên Udacity).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/SfyLGO5.jpg&#34; alt=&#34;&#34; title=&#34;Memory&#34;&gt;&lt;/p&gt;
&lt;p&gt;Với tình hình như vật thì lag và đứng màn hình là việc xảy ra thường xuyên, ảnh hưởng rất nhiều đến việc trải nghiệm và tăng sự ức chế mỗi khi code của mình lên khá nhiều. Nhưng rất may, mình không phải là người duy nhất ở trong tình trạng này. Mình đã tham khảo &lt;a href=&#34;https://stackoverflow.com/questions/27176353/android-studio-takes-too-much-memory&#34;&gt;ở đây&lt;/a&gt; để tìm cách giảm lượng ram sử dụng của Android Studio xuống nhưng không ảnh hưởng nhiều đến các tính năng ưu việt của nó. Trong đó có khá nhiều cách, mình đã thử qua nhiều các và thấy những cách sau đây khá hiệu quả:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Đầu tiên và quan trọng nhất: Đừng bao giờ chạy Android Virtual Device nếu bạn không muốn máy bạn bị đứng và phải hard reset. Hãy tìm một con smartphone android và chạy app trực tiếp trên đó.&lt;/li&gt;
&lt;li&gt;Tắt bớt những Plugin không cần thiết: Mình tắt những Plugin hỗ trợ Version Control. Thay vì trực tiếp sử dụng trong Android Studio, mình sử dụng trên terminal (mình chủ yếu sử dụng Git).&lt;/li&gt;
&lt;li&gt;Cài đặt lại kích thước tối đa cho Heap của Gradle: Việc này làm cho quá trình build của mình lâu hơn bình thường, nhưng bù lại thì nó đỡ tốn ram hơn.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ở trong link mình đã để ở trên, còn nhiều cách nữa để giảm lượng ram của Android Studio xuống, nhưng thường sẽ đánh đổi một ít về tính năng (Ví dụ như bật chế độ tiết kiệm pin trong Android Studio sẽ làm mất đi một số tính năng hộ trợ việc code trên IDE). Kết quả sau khi tùy chỉnh khá ổn. Đây là tình trạng bộ nhớ của máy mình khi mình đang viết bài này (mở Android Studio và 5 tab Google Chorme)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/iHPWr2M.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Như vậy là vấn đề đầu tiên đã được giải quyết xong. Bây giờ mình có thể tiếp tục học mà không phải ức chế vì lag nữa rồi.&lt;/p&gt;
&lt;p&gt;#Udacity&lt;/p&gt;
&lt;p&gt;Như mình đã nói đến ở bài viết trước, mình sẽ học một chuỗi course về Android trên Udacity, bao gồm 5 course:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/android-basics-user-interface--ud834&#34;&gt;Android Basics: User Interface&lt;/a&gt; (2 tuần)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/android-basics-user-input--ud836&#34;&gt;Android Basics: User Input&lt;/a&gt; (4 tuần)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/android-basics-multiscreen-apps--ud839&#34;&gt;Android Basics: Multiple App Screens&lt;/a&gt; (2 tháng)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/android-basics-networking--ud843&#34;&gt;Android Basics: Networking&lt;/a&gt; (5 tuần)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/android-basics-data-storage--ud845&#34;&gt;Android Basics: Data Storage&lt;/a&gt; (8 tuần)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thời gian học ở trên là thời gian đề nghị trong mỗi course, mình nghĩ mình sẽ đẩy nhanh tốc độ hơn vì mình đã có kinh nghiệm về lập trình trước rồi. Mình khá thích những khóa này vì những video bài giảng khá ngắn (trung bình khoảng 4 - 5 phút, thỉnh thoảng mới có những video 9 - 10 phút, còn nhiều hơn thì mình chưa thấy), cách dạy trực quan và sáng tạo (mình đã ngủ gật khi học khóa Android trên Coursera vì giảng lý thuyết nhiều quá), sau mỗi video hay nội dung mới đều có những câu hỏi để các bạn check lại những điều vừa học. Ngoài ra, các ví dụ và code mẫu của khóa đều có trên Github và được cập nhật thường xuyên, tránh được trường hợp ức chế vì nội dung khóa quá cũ. Udacity cũng có một forum để các bạn tiện đặt câu hỏi, chia sẻ app của mình và nhận những đánh giá từ những người học khác. Ngoài những khóa này, ngoài ra còn có chương trình Nanodegree  (đây là chương trình bao quát và chi tiết về Android của Google), tuy nhiên học phí khá đắt (200$ mỗi tháng, thời gian học dự kiến 1 năm).&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Mình sẽ dừng bài viết ở đây. Trong bài tiếp theo, mình sẽ chia sẻ về những gì mình đã học và làm được trong khóa đầu tiên Android Basics: User Interface. Về tình hình hiện tại thì mình đã học Android được 3 tuần. Mình đã hoàn thành 3 kh đầu tiên và đang tiếp tục học khóa thứ 4 Android Basics: Networking.  Như mọi lần, vì là một thằng Noob, mình rất mong nhận được những ý kiến đóng góp của các bạn ^_^.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Android for Noob</title>
      <link>https://incenger.github.io/post/learn/android-for-noob/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://incenger.github.io/post/learn/android-for-noob/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://i.imgur.com/WryYTJY.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Đây không phải là một bài viết chuyên sâu về Android. Tuy tiêu đề là “Android for noob”, đây cũng không phải là một bài hướng dẫn Android cho những người bắt đầu. Đây đơn thuần chỉ là những chia sẻ và trải nghiệm của một thằng noob (mình) khi học lập trình Android.&lt;/p&gt;
&lt;h1 id=&#34;tại-sao-lại-là-android&#34;&gt;Tại sao lại là Android?&lt;/h1&gt;
&lt;p&gt;Mình học Android vì … mình thích, vậy thôi. À ngoài ra mình cũng đang xài một con smartphone chạy hệ điều hành Android nên mình tranh thủ tận dụng luôn.&lt;/p&gt;
&lt;h1 id=&#34;mình-đã-có-gì&#34;&gt;Mình đã có gì?&lt;/h1&gt;
&lt;p&gt;Như tiêu đề, mình là một thằng noob. Vì vậy các bạn có lẽ cũng không nên bất ngờ quá nếu phần này ngắn quá.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ngôn ngữ lập trình: Hiện tại thì mình đang học và sử dụng chủ yếu C++. Ngoài ra mình cũng biết một ít về Java và Python. Java thì mình chỉ biết đủ để làm bài tập ở course &lt;a href=&#34;https://www.coursera.org/learn/algorithms-part1&#34;&gt;Algorithm&lt;/a&gt; trên Coursera. Python thì mình có biết qua khi học khóa &lt;a href=&#34;https://www.edx.org/course/cs50s-introduction-computer-science-harvardx-cs50x&#34;&gt;CS50&lt;/a&gt; trên EdX.&lt;/li&gt;
&lt;li&gt;Về Android: Ngoài chuyện mình biết dùng một con smartphone chạy Android và lúc trước thỉnh thoảng có nghịch root máy và up rom các kiểu thì ngoài ra mình chưa biết gì về Android.&lt;/li&gt;
&lt;li&gt;OOP: Mình có tìm hiểu qua và biết một số khái niệm cơ bản.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tóm lại, như đã nói, mình là một thằng noob.&lt;/p&gt;
&lt;h1 id=&#34;mình-bắt-đầu-như-thế-nào&#34;&gt;Mình bắt đầu như thế nào?&lt;/h1&gt;
&lt;p&gt;Ban đầu mình chọn khóa &lt;a href=&#34;https://www.coursera.org/learn/android-programming&#34;&gt;Programming Mobile Applications for Android Handheld Systems&lt;/a&gt; trên Coursera. Tuy nhiên, sau khi học tuần đầu tiên, mình thấy khóa này đã khá cũ và cách tiếp cận không phù hợp với mình. Vì vậy mình quyết định không học khóa này nữa mà tìm những khóa khác phù hợp hơn.&lt;/p&gt;
&lt;p&gt;Khóa học tiếp theo mình tìm đến là &lt;a href=&#34;https://in.udacity.com/interview-skill-certification/android-basics-user-interface--ud834&#34;&gt;Android Basics&lt;/a&gt; trên Udacity. Khóa này được đánh giá là cho những học viên chưa hề có kinh nghiệm lập trình trước đó, vì vậy mình nghĩ đây có thể là cách tiếp cận tốt hơn cho mình. Mình enroll khóa đầu tiên trong chuỗi những khóa của Android Basics là Android Basics: User Interface. Sau khi xem vài video đầu tiên, mình cảm thấy đây chính là khóa học phù hợp với mình. Ngay sau đó mình đã enroll luôn cả 4 khóa còn lại. Và như vậy hành trình Android của mình đã bắt đầu&amp;hellip;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Mình sẽ dừng ở đây vì mục đích của bài này chỉ là giới thiệu về những gì mình định viết. Trong những bài tiếp theo, mình sẽ chia sẻ những kiến thức, trải nghiệm mình có được cũng như những app mà mình đã làm được trong quá trình học. Vì là một thằng noob, mình luôn sẵn sàng đón nhận những ý kiến đóng góp cho bài viết của mình.&lt;/p&gt;
        
      </description>
    </item>
    
  </channel>
</rss>
