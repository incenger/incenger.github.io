<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fellowship-Optim on </title>
    <link>https://incenger.github.io/categories/fellowship-optim/</link>
    <description>Recent content in Fellowship-Optim on </description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Sat, 17 Apr 2021 19:14:34 +0700</lastBuildDate><atom:link href="https://incenger.github.io/categories/fellowship-optim/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Fellowship of the Optim: How I met my thesis</title>
      <link>https://incenger.github.io/post/fellowship_optim/where_am_i_now_1/</link>
      <pubDate>Sat, 17 Apr 2021 19:14:34 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/fellowship_optim/where_am_i_now_1/</guid>
      <description>
        
          &lt;p&gt;Nếu như đã đọc &lt;a href=&#34;https://incenger.github.io/post/fellowship_optim/hello_world_0/&#34;&gt;bài viết trước&lt;/a&gt;, các bạn sẽ biết mình đang làm thesis về đề tài Video Super Resolution. Thật ra đề tài này không phải là dự định ban đầu của mình, đúng hơn, mình còn chưa bao giờ nghĩ đến đề tài này cho đến khi gặp thầy hướng dẫn. Trong bài viết này, mình sẽ kể lại mình đã bắt đầu với thesis của mình như thế nào, và tình hình hiện tại của nó.&lt;/p&gt;
&lt;h3 id=&#34;mình-lên-ý-tưởng-không-hẳn-cho-thesis-của-mình-như-thế-nào&#34;&gt;Mình lên ý tưởng (không hẳn) cho thesis của mình như thế nào?&lt;/h3&gt;
&lt;p&gt;Mình khá hoang mang với việc làm thesis, và việc nghĩ đến nó thôi cũng làm mình lo lắng. Mặc dù mình đã có một ít kinh nghiệm về việc làm nghiên cứu, nhưng thẳng thắn mà nói thì mình chưa có một &amp;ldquo;công trình&amp;rdquo; hoàn chỉnh nào cả. Dự án ở môn Nghiên cứu khoa học thì không có kết quả đáng kể nào cả, còn dự án mình làm ở AI Lab thì vẫn chưa hoàn thành lúc mình quyết định xin nghỉ. Lúc đó, mình không định hình được mình sẽ cần phải làm gì có thể tạo nên một công trình nghiên cứu thành công cả. À thật ra về mặt lý thuyết thì mình biết, nhưng mình không biết phải làm mọi thứ như thế nào. Mình biết làm thesis chắc chắn sẽ là không phải là một con đường dễ dàng cho mình, nhưng trong những lựa chọn mình có, thì nó vẫn là lựa chọn mà mình cảm thấy tự tin nhất. Challenge accepted, bắt tay vào làm thôi.&lt;/p&gt;
&lt;p&gt;Những việc đầu tiên mình cần làm đó là tìm đề tài, tìm người làm thesis chung, và tìm người hướng dẫn. Lúc lên ý tưởng cho thesis, mình vẫn còn đang làm ở CinnamonAI và tập trung vào những bài toán liên quan đến Graph Neural Network (mình sẽ gọi tắt là GNN). Với việc đang là một chủ đề khá mới và hấp dẫn, mình nghĩ làm thesis về Graph Neural Network sẽ là một lựa chọn hợp lí. Nhưng tìm kiếm bài toán vốn không phải là điểm mạnh của mình. &amp;ldquo;Làm về Graph Neural Network, nhưng làm gì bây giờ?&amp;rdquo; - đây là câu hỏi mà mình luôn trăn trở trong suốt một thời gian dài. Mình suy nghĩ về một số hướng mình có thể làm, nhưng cảm thấy đều bế tắc cả. Đề xuất một network architecture mới -  mình chỉ nghĩ được đến việc áp dụng những architecture đã hoạt động hiệu quả trong những bài toán về Vision hay Natural Lanuage vào Graph, nhưng hầu như những sự kết hợp đó đều được được thực hiện. Mình cũng nhận thấy một vấn đề nho nhỏ là những dataset được dùng trong các papers về GNN rất là nhỏ, đặc biệt so với kích thước của model, nên mình nghĩ tìm cách đưa ra một dataset mới (kiểu như ImageNet) sẽ là một đóng góp đáng kể. Nhưng mình nghĩ, đó không phải là một hướng đi khả thi đối với mình. Mãi một thời gian sau, mình cũng vẫn loay hoay trong những suy nghĩ rối bời này. Lúc đó, nếu ai hỏi, thì mình cũng sẽ luôn chỉ trả lời là mình sẽ làm về GNN và không nói thêm được gì nữa.&lt;/p&gt;
&lt;p&gt;Vì không muốn áp lực lên bản thân quá nhiều, cộng với việc mình vẫn phải tập trung vào một số môn học ở trường, mình thường xuyên trì hoãn về việc tìm kiếm ý tưởng cho thesis. Lúc này, mình quyết định chuyển hướng qua việc đi tìm bạn làm chung vì dù sao hai người động não suy nghĩ thường sẽ tốt hơn một người, nhất là một người đang bế tắc :))). Mình bắt đầu đi rủ những đứa bạn mà mình nghĩ sẽ có thể hứng thú về Deep Learning để làm chung thesis. Và sau đó, sao nhỉ, là một chuỗi những lời từ chối khi những người mình hỏi nếu không phải đã quyết định làm một mình, thì cũng đã có nhóm sẵn rồi. Lúc đó, mình cảm giác như mình đang là một diễn viên hài trong một bộ phim và khán giả đang cười vào tình huống trớ trêu này của mình.&lt;/p&gt;
&lt;p&gt;Mình tạm gác hai việc tìm người làm chung và tìm ý tưởng qua một bên, và bắt đầu đi liên hệ với những thầy cô mình biết để tìm giáo viên hướng dẫn. Mình lên hệ thầy Triết, nói về việc mình đang dự định làm về Graph Neural Network, và hỏi thầy có biết những thầy cô nào có thể giúp mình trong đề tài này không. Vì mình cũng chưa có bài toán cụ thể, nên thầy cũng không giúp gì được cho mình nhiều. Thầy khuyên mình cứ suy nghĩ thêm, khi nào có hướng đi cụ thể thì thầy sẽ giúp được và động viên mình. Mình không biết thầy có cảm nhận được tinh thần đang chạm đáy của mình lúc đó qua những tin nhắn bình thường hay không, nhưng những lời động viên của thầy giống như những tia sáng lé loi duy nhất mà mình cảm nhận được trong suốt khoảng thời gian đó. Và đúng là sau những lời động viên thì mọi chuyện của mình bắt đầu trở lại đúng quỹ đạo thật.&lt;/p&gt;
&lt;p&gt;Một đứa bạn khác của mình (mà mình không nghĩ là sẽ làm thesis về Deep Learning) có nhắn hỏi về việc mình đã có nhóm chung với ai chưa. Và thế là mình đã tìm được người làm chung theo cái cách mà mình không ngờ nhất =))). Tiếp theo, mình liên hệ với thầy Sơn - người dạy mình 2 môn Computer Graphics và Computer Vision - để hỏi về việc hướng dẫn luận văn. Sau khi nghe mình chia sẻ về việc đang cảm thấy bế tắc trong việc tìm kiếm đề tài, thầy đã đề xuất cho mình một số đề tài. Sau một thời gian suy nghĩ và bàn bạc với bạn mình, mình đã quyết định chọn chủ đề về Video Super Resolution (một trong những chủ đề mà thầy mình đề xuất). Và thế là đề tài của mình ra đời. Nhìn lại, có lẽ vấn đề của mình không phải là việc tìm ra bài toán, vì lúc mình chọn Video Super Resolution mình cũng đã nghĩ ra được hướng đi nào đâu, mà là tìm một người có thể dẫn dắt mình, giúp mình có thể tự tin với lựa chọn dù chưa biết phía trước điều gì đang chờ đón.&lt;/p&gt;
&lt;h3 id=&#34;mình-bắt-đầu-như-thế-nào-&#34;&gt;Mình bắt đầu như thế nào ?&lt;/h3&gt;
&lt;p&gt;Vừa rồi là phần hồi tưởng của mình về quá khứ, phần tiếp theo sẽ về hiện tai và mình nghĩ sẽ một số điều thú vị mà các bạn có thể thu về được cho mình. (thật ra nó cũng là quá khứ nhưng vẫn tiếp tục trong hiện tại - kiểu như thì hiện tại hoàn thành trong tiếng Anh vậy :)) ). Mình hiểu Super Resolution là làm gì (mình nghĩ đa phần mọi người cũng sẽ hiểu) nhưng mình chưa tìm hiểu sâu về đề tài này. Trong những course Deep Learning mà mình học, mình nhớ cũng không có course nào sử dụng bài toán này làm ví dụ (nếu các bạn biết có course nào thì có thể comment để mình cập nhật lại nhé, vì lâu rồi mình cũng không tìm những course Deep Learning mới). Vì vậy, mình quyết định bằng cách đơn giản nhất là &amp;hellip; đọc paper :)). Và đây là cách mình tìm kiếm papers và những công cụ mình sử dụng kèm theo để tổng hợp kiến thức.&lt;/p&gt;
&lt;p&gt;Để tìm papers thì mình sẽ sử dụng &lt;a href=&#34;https://scholar.google.com/&#34;&gt;Google Scholar&lt;/a&gt;,  &lt;a href=&#34;https://www.connectedpapers.com/&#34;&gt;Connected Papers&lt;/a&gt;  và &lt;a href=&#34;https://paperswithcode.com/&#34;&gt;Paperswithcode&lt;/a&gt;. Google Scholar để mình có thể tìm paper chính xác hơn, thay vì chỉ search bằng Google thông thường. Connected Papers để tìm những papers liên quan đến một papers nào đó và Paperswithcode giúp mình tìm những papers đang là &amp;ldquo;state-of-the-art&amp;rdquo; và nhanh chóng biết được papers đó có code sẵn không. Mình sẽ lấy một ví dụ cho các bạn dễ hiểu.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Đầu tiên, mình sẽ thử search Google Scholar với từ khóa &amp;ldquo;Video Super Resolution&amp;rdquo;. Mình thường sẽ chọn những papers gần đây hoặc có số citation cao để bắt đầu. Mình chọn paper &lt;strong&gt;Video super-resolution with convolutional neural networks&lt;/strong&gt;.
&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/google_scholar_search.png&#34; alt=&#34;Google Scholar&#34;&gt;&lt;/li&gt;
&lt;li&gt;Tiếp theo, mình có thể sử dụng Connected Papers để tìm những papers liên quan đến papers này.
&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/connected_papers.png&#34; alt=&#34;Connected Papers&#34;&gt;&lt;/li&gt;
&lt;li&gt;Mình sẽ dùng thêm Paperswithcode để tìm, qua đó sẽ biết thêm được những dataset đang được sử dụng cho bài toán này và các phương pháp hiện nay đang có kết quả như thế nào.
&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/paperswithcode.png&#34; alt=&#34;Papers With Code&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sau khi tìm xong thì mình bắt đầu đọc paper thôi. Về cách đọc paper thì đã có rất nhiều hướng dẫn chi tiết và cách mình đọc paper thì cũng không có gì khác biệt lắm. Mình thường đọc và sử dụng Obsidian.md để take notes lại. Mình thường take note theo 4 câu hỏi chính: &amp;ldquo;Bài toán ở đây là gì?&amp;rdquo;, &amp;ldquo;Phương án giải quyết nó như thế nào?&amp;rdquo;, &amp;ldquo;Kết quả ra sao?&amp;rdquo;, &amp;ldquo;Mình có thể tái sử dụng hay mở rộng ý tưởng ở đây như thế nào?&amp;rdquo;. Mình khá thích Obsidian.md là mình có thể link những note lại với nhau và tạo thành một cái knowledge graph. Công cụ này giúp mình kết nối những papers lại với nhau dễ dàng hơn một tí (vẫn tốn công sức ban đầu, nhưng sau này nếu các bạn có xem lại thì sẽ dễ có được góc nhìn tổng quan hơn).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/obsidian_note.png&#34; alt=&#34;Ví dụ về một paper note&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/obsidian_graph.png&#34; alt=&#34;Tính năng Graph của Obsidian.md&#34;&gt;&lt;/p&gt;
&lt;p&gt;Ngoài phần papers ra thì một phần quan trọng không kém đó là code. Trong lúc tìm paper, mình cũng thường ưu tiên những papers có code (chính chủ hoặc re-implementation đều được, bạn có thể dùng Paperswithcode để tìm). Mình sẽ cần phải implement và thử nghiệm khá nhiều phương pháp, nên mình cần những codebase thuận tiện cho việc mở rộng. Thuận tiện ở đây mang ý nghĩa: mình cần có tốn nhiều công sức để thêm một architecture hoàn toàn mới không; những utility functions như training, evaluation có tái sử dụng được không, &amp;hellip; (Vì mình lười nên tự implement luôn là phương án cuối cùng của mình :)) ). Cuối cùng, mình quyết định lựa chọn &lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt; vì nó đáp ứng được khá nhiều tiêu chí ở trên, thiết kế khá đơn giản, và cũng đang được maintained. Mình không giỏi về code lắm, nên mình dành khá nhiều thời gian để tìm hiểu và học về repo này. Cách mình học thì cũng không có gì đặc biệt lắm, cứ chạy code, chèn cái snippet này vào &lt;code&gt;__import__(&#39;ipdb&#39;).set_trace()&lt;/code&gt; và chạy từng dòng để hiểu mọi thứ hoạt động như thế nào =)))) (Nó hiệu quả hơn &lt;code&gt;print(&amp;quot;What the heck?&amp;quot;)&lt;/code&gt; nhiều đấy, các bạn cứ thử xem :)) ).&lt;/p&gt;
&lt;h3 id=&#34;thesis-đến-đâu-rồi--&#34;&gt;Thesis đến đâu rồi :&#39;( ?&lt;/h3&gt;
&lt;p&gt;Trong giai đoạn này (sau khi kết thúc kì 1 năm 4, khoảng từ tháng 1/2021) mình cũng khá là trì hoãn trong việc làm thesis. Sau đây là một số lí do biện hộ cho việc mình trì hoãn =))):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mình làm full-time nên ban ngày mình sẽ tập trung hoàn toàn vào những bài toán ở công ty, thời gian còn lại thì mình muốn nghỉ ngơi. Ngoài ra, thỉnh thoảng mình cũng thích làm công việc của công ty hơn là làm thesis :))&lt;/li&gt;
&lt;li&gt;Mình cần hoàn thành thesis proposal. Do vậy mình dành thời gian chủ yếu để đọc papers và trì hoãn việc code lại. Hậu quả là sau khi hoàn thành proposal thì mình chưa thật sự chạy thử một model nào cả&lt;/li&gt;
&lt;li&gt;Codebase &lt;code&gt;MMEditing&lt;/code&gt; khá lớn, mình không biết nên bắt đầu từ đâu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Trong thời gian này mình còn nhận ra được một bài học khá thú vị. Mình đọc ở đâu đó lời khuyên là bạn nên làm 2 projects cùng một lúc, để nếu có một cái bế tắc thì bạn sẽ cảm thấy mình productive khi làm cái còn lại. Mình thấy lời khuyên này khá đúng, nhưng chỉ là, mình lại gặp bế tắc ở cả 2 projects (công ty và thesis) cùng một lúc. Kết cục là mình cảm giác như một thằng phế vậy =)) (Nếu các bạn muốn nghe về chuyện projects ở công ty thì cứ comment nhé, mình sẽ kể ở một bài khác, nó cũng là một bài học đau thương cho mình). Đây là biểu đồ tâm trạng mỗi ngày của mình trong thời gian đó (màu xanh lá cây là ổn, màu xanh nhạt là không ổn, màu cam là tệ).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://incenger.github.io/img/2021/how_i_met_my_thesis_1/mood.jpg&#34; alt=&#34;Thống kê cảm xúc của mình trong tháng 3/2021. Mình dùng app Daylio&#34;&gt;&lt;/p&gt;
&lt;p&gt;Một bài học nữa (mình nghĩ chắc các bạn cũng nghe nhiều rồi) mà mình rút ra được là không nên để những nỗi sợ ban đầu làm bạn chùn bước. Mình đã lo sợ trước cái thesis proposal, giữa một cái codebase mà mình nghĩ chắc mình sẽ không hiểu được, nhưng từng bước một, mình dần dần vượt qua được những chướng ngại đó. Đây là bài học của một người bình thường (mình nghĩ đúng hơn là hơi &amp;ldquo;phế&amp;rdquo;) nên mình nghĩ có thể nó sẽ dễ đồng cảm với mọi người hơn.&lt;/p&gt;
&lt;p&gt;Tóm lại, về thesis, hiện tại thì mình đã hoàn thành xong thesis proposal, đã hiểu code &lt;code&gt;MMEditing&lt;/code&gt;, implement xong một baseline model và đang train để xem kết quả như thế nào =))). Đây là giai đoạn mình thích nhất: được thử nghiệm nhiều ý tưởng và cầu nguyện mỗi lần train model =))))&lt;/p&gt;
&lt;p&gt;Bài viết hôm nay sẽ dài hơn một tí, vì mình dự định mình sẽ viết mỗi tuần 1 bài (chắc là vào cuối tuần). Nếu mình rảnh thì mình có thể viết nhiều hơn, nhưng mình không hứa chắc được, phải làm mới có thứ mà chia sẻ chứ :)))). Những bài viết sau mình sẽ viết cụ thể mình đang làm gì, vấn đề mình gặp phải và mình giải quyết nó như thế nào. Đưới đây là một ví dụ (mà mình mới giải quyết xong hôm nay)&lt;/p&gt;
&lt;p&gt;Khi mình evalute kết quả super resolution bằng việc sử dụng thuật toán cực kì đơn giản là resize bằng bicubic interpolation, kết quả PSNR (Peak Signal to Noise Ratio) của mình khá là cao, khoảng 31 db, trong khi số liệu trong các papers cũng chỉ ở khoảng 26 db. Mình bắt đầu kiểm tra lại mọi thứ:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code evaluation đã chính xác. Mình dùng hàm có sẵn trong &lt;code&gt;MMEditing&lt;/code&gt; nên xác suất sai là khá thấp. Mình kiểm tra thêm trong phần issues của repo thử xem có cái nào liên quan đến PSNR luôn không cho chắc&lt;/li&gt;
&lt;li&gt;Mình evaluate thêm kết quả của model hiện tại mình đang train, ra được PSNR khoảng 33 db, cao hơn khá nhiều so với model trong một số papers trong khi model của mình cũng chỉ là baseline. Lúc này mình bắt đầu nghĩ là có thể nằm ở data.&lt;/li&gt;
&lt;li&gt;Mình visualize kết quả high resolution ra và thấy kết quả cũng không quá tốt, và đạt PSNR cao như vậy thì rõ ràng là có vấn đề.&lt;/li&gt;
&lt;li&gt;Mình kiểm tra thêm metric khác là SSIM (Structural Similarity Index Measure) và thấy kết quả của metrics này khá tương đồng với các papers, điều này có nghĩa là cách mình dùng PSNR có vấn đề&lt;/li&gt;
&lt;li&gt;Mình nhớ lại là một số papers evaluate PSNR trên Y channel trong định dạng YCbCr thay vì RGB như thông thường. Mình implement hàm để covert ảnh sang YCbCr và thử lại. Kết quả ra đúng như mình mong đợi -&amp;gt; Problem solve :))).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;À còn một điều nữa mà mình cần làm, là tìm hiểu về định dạng màu YCbCr và tại sao PSNR lại không hoạt động tốt với định dạng RGB. Mình sẽ chia sẻ sau khi mình hiểu nhé :&amp;quot;&amp;gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>The Fellowship of the Optim: Hello World</title>
      <link>https://incenger.github.io/post/fellowship_optim/hello_world_0/</link>
      <pubDate>Wed, 14 Apr 2021 23:42:14 +0700</pubDate>
      
      <guid>https://incenger.github.io/post/fellowship_optim/hello_world_0/</guid>
      <description>
        
          &lt;blockquote&gt;
&lt;p&gt;Các bạn có thể tìm đọc tất cả bài viết của series này tại &lt;a href=&#34;https://incenger.github.io/categories/fellowship-optim/&#34;&gt;đây&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Mình sẽ bắt đầu bằng cách cung cấp một số thông tin cơ bản nhất, để bạn có thể biết được mình là ai, và những bài viết này nhằm mục đích gì. Và cách bắt đầu hiệu quả nhất theo mình nghĩ là những câu hỏi.&lt;/p&gt;
&lt;h3 id=&#34;tại-sao-lại-là-the-fellowship-of-the-optim&#34;&gt;Tại sao lại là The Fellowship of the Optim?&lt;/h3&gt;
&lt;p&gt;Mình lấy ý tưởng từ The Lord of the Rings - một trong những tác phẩm mình rất yêu thích. Mình thấy một phần nào đó của mình trong Frodo, khi vốn là một người vô năng nhưng lại được giao cho trọng trách lớn nhất. Giống như cách Frodo luôn tự vấn về bản thân, mình cũng hay nghĩ tại sao mình lại có được những gì mình có hiên tại. Ngoài ra, mình thấy cuộc hành trình tiêu hủy chiếc nhẫn, chông gai và đầy cạm bẫy, giống như hành trình một Optimizer đi tìm đến một điểm cực trị thích hợp vậy. Và mình cũng thích từ Fellowship, vì mình mong muốn tìm được những người đồng hành với mình trong những cuộc hành trình tiếp theo.&lt;/p&gt;
&lt;h3 id=&#34;tại-sao-mình-lại-có-ý-tưởng-viết-những-bài-viết-này&#34;&gt;Tại sao mình lại có ý tưởng viết những bài viết này?&lt;/h3&gt;
&lt;p&gt;Mình nghĩ mọi người thỉnh thoảng sẽ có cảm giác giống mình, là cảm giác nửa năm hay một năm trôi qua quá nhanh và khi nhìn lại thì nhận ra mình chưa làm được gì nhiều. Một cách để làm cảm giác đó trở nên ít tồi tệ đi là thêm vào dòng thời gian của mình những cột mốc cụ thể. Những bài viết này đối với mình chính là những cột mốc cho một giai đoạn đặc biệt mà mình nghĩ mình sẽ chỉ được trải nghiệm một lần trong đời&lt;/p&gt;
&lt;h3 id=&#34;mình-là-ai-mình-đang-làm-gì-và-mình-sẽ-viết-những-gì&#34;&gt;Mình là ai, mình đang làm gì, và mình sẽ viết những gì?&lt;/h3&gt;
&lt;p&gt;Các bạn có thể tìm đươc thông tin của mình thông qua những mạng xã hội đính kèm ở blog này. Vì blog này sẽ liên quan đến Deep Learning, nên mình sẽ chia sẻ một chút về hành trình của mình với Deep Learning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mình bắt đầu chú ý đến Deep Learning vào khoảng giữa kì 2 của năm thứ nhất (2018), mình cũng bắt đầu bằng những khóa học trên Coursera giống mọi người. Nhưng lúc đó, mình cứ mãi theo đuổi việc hoàn thành những khóa học mà bỏ quên việc hiểu sâu vào bản chất của Machine Learning và Deep Learning, và điều đó để lại hậu quả xấu sau này.&lt;/li&gt;
&lt;li&gt;Đầu năm 2 đại học, mình có cơ hội làm một project Deep Learning đầu tiên trong môn Nghiên cứu khoa học. Đó là bài toán về phát hiện xe bất thường trên cao tốc của NVIDIA AI City Challenge. Lúc đó mình rất phấn khởi, nhưng ngay lập tức sau đó ăn hành vì bị choáng ngợp trước việc cài đặt CUDA, cài đặt thư viện, chạy model,&amp;hellip;. Do lúc học những khóa học Deep Learning, mình chỉ tập trung vào việc hoàn thành bài tập mà không tìm hiểu sâu về bài toán, nên khi làm project này, sau khi clone được code của một paper có sẵn, thêm thắt chút đỉnh, mình không biết làm gì thêm nữa. Và sau khi kết thúc dự án này, mình cảm thấy chán Deep Learning, khi mình đã dành rất nhiều thời gian cho nó, nhưng lại luôn có cảm giác mình chẳng thật sự hiểu gì&lt;/li&gt;
&lt;li&gt;Sau dự án này, mình apply vào phòng thí nghiệm AI Lab của trường với mục đích sẽ được học hỏi và củng cố lại kiến thức của mình, và cũng thử sức với một bài toán mới lạ hơn trong lĩnh vực Speech Processing. Nhưng trái với những gì mình trông đợi, mình không nhận được nhiều sự hướng dẫn, mà chủ yếu phải tự mày mò tìm hiểu. Mình cứ dần chìm trong biển kiến thức mênh mông đó. Mình làm được trong Lab khoảng 6 tháng, và những gì mình làm được chỉ là đi thu thập dữ liệu text một cách bất cẩn, sau đó viết một vài cái rule-based (chủ yếu là regex) để làm text normalization (cho Text-to-speech system). Cuối năm 2019, mình xin nghỉ Lab, thu về cho mình thêm một dự án thất bại và bị trầm cảm. (Trong lúc này mình cũng được phỏng vấn thực tập ở Google, nhưng rồi cũng tạch :)) )&lt;/li&gt;
&lt;li&gt;Sau khi nghỉ ở Lab, mình định chuyển hướng sang học những kĩ năng Software Engineering để có thể tìm được vị trí thực tập ở năm 3. Mình vô tình thấy chương trình AI Bootcamp của CinnamonAI. Lúc đó mình đã cảm thấy quá chán nản với AI và Deep Learning, nên mình cũng không định đăng kí. Nhưng sau khi đọc qua thử chương trình, mình thấy trong bootcamp có vẻ chú trọng rất nhiều vào những kiến thức nền tảng - thứ mà mình luôn cảm thấy thiếu sót. Và mình quyết định cho AI thêm một cơ hội nữa. Và hóa ra đó là một quyết định làm thay đổi mình hoàn toàn. Mình may mắn thể hiện tốt trong Bootcamp và sau đó được offered internship và sau đó trở thành nhân viên chính thức. Có thể nói mình bắt đầu &amp;ldquo;học lại&amp;rdquo; mọi thứ về AI và Deep Learning từ Bootcamp của CinnamonAI&lt;/li&gt;
&lt;li&gt;Về quá khứ như vậy là đủ rồi, nếu các bạn có hứng thú thì mình sẽ viết thêm về những bài học mình học được từ quá trình đau thương đó. Hiện tại, về Deep Learning, mình có những kinh nghiệm nhỏ trong một số bài toán sau
&lt;ul&gt;
&lt;li&gt;Ở Bootcamp của CinnamonAI, mình làm về bài toán Automatic Colorization, nhưng chỉ trong 2 tuần nên mình cũng không tự tin là mình hiểu nhiều lắm.&lt;/li&gt;
&lt;li&gt;Trong quá trình làm việc ở CinnamonAI, mình làm chủ yếu về Deep Metric Learning và Graph Neural Network.&lt;/li&gt;
&lt;li&gt;Công việc hiện tại của mình bao gồm bài toán Detection và Segmentation.&lt;/li&gt;
&lt;li&gt;Mình đang làm luận văn về đề tài Video Super Resolution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Các bạn có thể thấy là mình thật sự không có một định hướng cụ thể nào cả, khi những bài toàn của mình thuộc khá nhiều chủ đề so với kĩ năng và kinh nghiệm hiện có của mình :))))&lt;/p&gt;

        
      </description>
    </item>
    
  </channel>
</rss>
